library(foreign)
library(MASS)
dat <- read.dta("https://stats.idre.ucla.edu/stat/data/ologit.dta")
m <- polr(apply ~ pared, data = dat)
summary(m)
dat
shape(dat)
type(dat)
typeof(dat)
len(dat)
length(dat)
head(dat)
dim(dat)
m <- polr(apply ~ pared, data = dat)
summary(m)
head(dat)
data$test <- sapply(data$apply, function(x) {
if (x == "unlikey") {
return(0)
}
})
data$categoria
dat$categoria
dat$test <- sapply(dat$apply, function(x) {
if (x == "unlikey") {
return(0)
}
})
head(dat)
categorias <- unique(dat$apply)
categorias
categorias[0]
categorias[1]
categorias[2]
categorias[3]
if (x == categorias[3]) {
return(0)
}
dat$test <- sapply(dat$apply, function(x) {
if (x == categorias[3]) {
return(0)
}
})
head(dat)
dat$test <- sapply(dat$apply, function(x) {
if (x == categorias[3]) {
return(0)
} elif (x == categorias[2]) {
return(1)
} elif (x == categorias[1]) {
return(2)
}
})
head(dat)
dat$test <- sapply(dat$apply, function(x) {
if (x == categorias[3]) {
return(0)
} elif (x == categorias[2]) {
return(1)
}
})
dat$test <- sapply(dat$apply, function(x) {
if (x == categorias[3]) {
return(0)
} elif (x == categorias[2]) {
return(1)
}
})
dat$test <- sapply(dat$apply, function(x) {
if (x == categorias[3]) {
return(0)
} elif (x == categorias[2]) {
return(1)
}
})
dat$test <- sapply(dat$apply, function(x) {
if (x == categorias[3]) {
return(0)
} else if (x == categorias[2]) {
return(1)
}
})
dat$test <- sapply(dat$apply, function(x) {
if (x == categorias[3]) {
return(0)
} else if (x == categorias[2]) {
return(1)
} else if (x == categorias[1]) {
return(2)
}
})
head(dat)
# Regressing Consistency(n) w.r.t. Score(n-1)
model1h <- lm(test ~ pared, data = dat)
summary(model1h) # => Positive correlation is significant
summary(m)
g1 <- ggplot(dat, aes(pared, test)) +
#  geom_point(alpha = 1/8) +
#  theme_bw() +
#  xlab("Score(n-1)") +
#  ylab("Consistency(n)") +
stat_smooth(method='lm', formula = y~poly(x,1))
library(ggplot2)
g1 <- ggplot(dat, aes(pared, test)) +
#  geom_point(alpha = 1/8) +
#  theme_bw() +
#  xlab("Score(n-1)") +
#  ylab("Consistency(n)") +
stat_smooth(method='lm', formula = y~poly(x,1))
g1
g1 <- ggplot(dat, aes(pared, test)) +
geom_point(alpha = 1/8) +
#  theme_bw() +
#  xlab("Score(n-1)") +
#  ylab("Consistency(n)") +
stat_smooth(method='lm', formula = y~poly(x,1))
g1
newdat <- data.frame(pared=c(0,1))
(phat <- predict(object = m, newdat, type="p"))
phat
## store table
(ctable <- coef(summary(m)))
## calculate and store p values
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
## combined table
(ctable <- cbind(ctable, "p value" = p))
(ci <- confint(m))
exp(cbind(coef(m),t(ci)))
setwd("~/Repositorios/SODCL/R")
library(sjmisc)
library(ggplot2)
df1 = read.csv("../Data/humans_only_absent.csv")
df1 <- df1[complete.cases(df1), ]
# Pearson correlation
cor(df1$Consistency, df1$Score_LAG1) # => 0.23
# Regressing Consistency(n) w.r.t. Score(n-1)
model1h <- lm(Consistency ~ Score_LAG1, data = df1)
summary(model1h) # => Positive correlation is significant
g1 <- ggplot(df1, aes(Score_LAG1, Consistency)) +
geom_point(alpha = 1/8) +
theme_bw() +
xlab("Score(n-1)") +
ylab("Consistency(n)") +
stat_smooth(method='lm', formula = y~poly(x,1))
g1
m <- polr(Consistency ~ Score_LAG1, data = df1)
summary(df1$Consistency)
test <- cut(df1$Consistency, breaks = c(0.31, 0.86))
test
table(test)
test <- cut(df1$Consistency, breaks = c(0, 0.31, 0.86, 1))
table(test)
df1$test <- cut(df1$Consistency, breaks = c(0, 0.31, 0.86, 1))
df1$Consistency_ordinal <- cut(df1$Consistency, breaks = c(0, 0.31, 0.86, 1))
m <- polr(Consistency_ordinal ~ Score_LAG1, data = df1)
summary(m)
df1$Consistency_ordinal <- cut(df1$Consistency,
breaks = c(0, 0.31, 0.86, 1),
labels = c("inconsistent", "moderately consistent", "consistent")
)
m <- polr(Consistency_ordinal ~ Score_LAG1, data = df1)
summary(m)
## store table
(ctable <- coef(summary(m)))
## calculate and store p values
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
## combined table
(ctable <- cbind(ctable, "p value" = p))
(ci <- confint(m))
exp(cbind(coef(m),t(ci)))
newdat <- data.frame(pared=c(0,1))
(phat <- predict(object = m, newdat, type="p"))
phat
(ci <- confint(m))
exp(cbind(coef(m),t(ci)))
(ci <- confint(m))
exp(cbind(coef(m),t(ci)))
anova(df1$Score_LAG1, df1$Consistency_ordinal)
boxplot(df1$Score_LAG1~df1$Consistency_ordinal)
summary(df1$Consistency)
df1$Consistency_ordinal <- cut(df1$Consistency,
breaks = c(0, 0.31, 0.86, 0.99, 1),
labels = c("inconsistent", "moderately consistent", "consistent", "highly consistent")
)
boxplot(df1$Score_LAG1~df1$Consistency_ordinal)
m <- polr(Consistency_ordinal ~ Score_LAG1, data = df1)
summary(m)
## store table
(ctable <- coef(summary(m)))
## calculate and store p values
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
## combined table
(ctable <- cbind(ctable, "p value" = p))
(ci <- confint(m))
exp(cbind(coef(m),t(ci)))
boxplot(df1$Score_LAG1~df1$Consistency_ordinal)
df1$Consistency_ordinal <- cut(df1$Consistency,
breaks = c(0, 0.31, 0.86, 1),
labels = c("inconsistent", "moderately consistent", "consistent")
)
boxplot(df1$Score_LAG1~df1$Consistency_ordinal)
by(df1$Score_LAG1, df1$Consistency_ordinal, shapiro.test)
## Finding odds
(ci <- confint(m))
exp(cbind(coef(m),t(ci)))
## Cutting the Consistency variable into three levels
summary(df1$Consistency)
df1$Consistency_ordinal <- cut(df1$Consistency,
breaks = c(0, 0.31, 0.86, 1),
labels = c("inconsistent", "moderately consistent", "consistent")
)
## Drawing boxplot
boxplot(df1$Score_LAG1~df1$Consistency_ordinal)
## Running OLR model
m <- polr(Consistency_ordinal ~ Score_LAG1, data = df1)
summary(m)
## store table
(ctable <- coef(summary(m)))
## calculate and store p values
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
## combined table
(ctable <- cbind(ctable, "p value" = p))
## Finding odds
(ci <- confint(m))
exp(cbind(coef(m),t(ci)))
## Drawing boxplot
boxplot(df1$Score_LAG1~df1$Consistency_ordinal,
xlab="Consistency")
## Drawing boxplot
boxplot(df1$Score_LAG1~df1$Consistency_ordinal,
xlab="Consistency",
ylab="Score on previous round"
)
